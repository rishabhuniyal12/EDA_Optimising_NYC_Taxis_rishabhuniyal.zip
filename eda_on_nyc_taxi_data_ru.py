# -*- coding: utf-8 -*-
"""EDA on NYC Taxi Data_ru.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/183R2gg6TVgW3oSWyWETtkOZMX22ilOeO

1.Data Preparation for NYC Taxi assignment
"""

import pandas as pd
import requests
import pyarrow.parquet as pq
from io import BytesIO

# Base URL for NYC TLC data
base_url = "https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2023-XX.parquet"

# Define the sampling fraction (e.g., 10%)
sample_fraction = 0.1

# List to store sampled DataFrames
sampled_dfs = []

# Loop through all 12 months
for month in range(1, 13):
    month_str = str(month).zfill(2)  # Ensure two-digit month format (e.g., 01, 02, ..., 12)
    file_url = base_url.replace("XX", month_str)  # Replace XX with actual month number
    print(f"Downloading: {file_url}")

    # Download the Parquet file using requests
    response = requests.get(file_url)

    if response.status_code == 200:
        df = pd.read_parquet(BytesIO(response.content), engine="pyarrow")  # Read file into DataFrame

        # Sample 10% of the data
        sampled_df = df.sample(frac=sample_fraction, random_state=42)
        sampled_dfs.append(sampled_df)
    else:
        print(f"❌ Failed to download: {file_url}")

# Combine all sampled DataFrames
combined_df = pd.concat(sampled_dfs, ignore_index=True)

# Save the merged dataset to Google Colab storage
combined_df.to_parquet("/content/nyc_taxi_sampled_2023.parquet")
combined_df.to_csv("/content/nyc_taxi_sampled_2023.csv", index=False)

print("\n✅ Data Sampling Completed! Files saved in Colab:")
print("- /content/nyc_taxi_sampled_2023.parquet")
print("- /content/nyc_taxi_sampled_2023.csv")

from google.colab import files

# Download the CSV file
files.download("/content/nyc_taxi_sampled_2023.csv")

# Download the Parquet file (if needed)
files.download("/content/nyc_taxi_sampled_2023.parquet")

"""2.Data Cleaning"""

# Standardize column names
combined_df.columns = (
    combined_df.columns.str.strip()  # Remove any extra spaces
    .str.lower()  # Convert to lowercase
    .str.replace(" ", "_")  # Replace spaces with underscores
    .str.replace(r"[^a-zA-Z0-9_]", "", regex=True)  # Remove special characters
)

print(" Column names standardized:")
print(combined_df.columns)

# Check for missing values
missing_values = combined_df.isnull().sum()
missing_percentage = (missing_values / len(combined_df)) * 100

# Display missing values
missing_df = pd.DataFrame({"Missing Values": missing_values, "Percentage": missing_percentage})
print("Missing Value Analysis:")
print(missing_df[missing_df["Missing Values"] > 0])

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

# Define numerical columns for outlier detection
num_cols = ["fare_amount", "tip_amount", "passenger_count", "trip_distance", "total_amount"]

# Boxplot to detect outliers visually
plt.figure(figsize=(12, 6))
sns.boxplot(data=combined_df[num_cols])
plt.xticks(rotation=45)
plt.title("Boxplot for Outlier Detection")
plt.show()

# Using Interquartile Range (IQR) method
Q1 = combined_df[num_cols].quantile(0.25)
Q3 = combined_df[num_cols].quantile(0.75)
IQR = Q3 - Q1

# Define lower and upper bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Identify outlier counts
outliers = ((combined_df[num_cols] < lower_bound) | (combined_df[num_cols] > upper_bound)).sum()
print("\n Outlier Detection Results:")
print(outliers)

"""3.Exploratory Data Analysis"""

!pip install geopandas

# Identify categorical and numerical columns
categorical_cols = combined_df.select_dtypes(include=['object', 'category']).columns.tolist()
numerical_cols = combined_df.select_dtypes(include=['int64', 'float64']).columns.tolist()

print(" Categorical Variables:", categorical_cols)
print(" Numerical Variables:", numerical_cols)

import seaborn as sns
import matplotlib.pyplot as plt

# Convert timestamps to datetime format
combined_df['tpep_pickup_datetime'] = pd.to_datetime(combined_df['tpep_pickup_datetime'])
combined_df['hour'] = combined_df['tpep_pickup_datetime'].dt.hour
combined_df['day_of_week'] = combined_df['tpep_pickup_datetime'].dt.day_name()
combined_df['month'] = combined_df['tpep_pickup_datetime'].dt.month_name()

# Plot pickups by hour
plt.figure(figsize=(12, 6))
sns.countplot(x='hour', data=combined_df, palette='coolwarm')
plt.title("Taxi Pickups by Hour of the Day")
plt.xlabel("Hour of the Day")
plt.ylabel("Number of Pickups")
plt.xticks(rotation=45)
plt.show()

# Plot pickups by day
plt.figure(figsize=(12, 6))
sns.countplot(x='day_of_week', data=combined_df, order=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])
plt.title("Taxi Pickups by Day of the Week")
plt.xlabel("Day of the Week")
plt.ylabel("Number of Pickups")
plt.show()

# Plot pickups by month
plt.figure(figsize=(12, 6))
sns.countplot(x='month', data=combined_df, palette='viridis')
plt.title("Taxi Pickups by Month")
plt.xlabel("Month")
plt.ylabel("Number of Pickups")
plt.xticks(rotation=45)
plt.show()

# Remove invalid data
combined_df = combined_df[
    (combined_df['fare_amount'] > 0) &
    (combined_df['trip_distance'] > 0) &
    (combined_df['tip_amount'] >= 0)
]

print(" Filtered dataset size:", combined_df.shape)

# Aggregate total fare per month
monthly_revenue = combined_df.groupby('month')['total_amount'].sum().reset_index()

# Plot monthly revenue trends
plt.figure(figsize=(12, 6))
sns.barplot(x='month', y='total_amount', data=monthly_revenue, palette='Blues_r')
plt.title("Monthly Revenue Trends")
plt.xlabel("Month")
plt.ylabel("Total Revenue ($)")
plt.xticks(rotation=45)
plt.show()

# Define quarters
combined_df['quarter'] = combined_df['tpep_pickup_datetime'].dt.to_period("Q")
quarterly_revenue = combined_df.groupby('quarter')['total_amount'].sum().reset_index()

# Plot quarterly revenue proportions
plt.figure(figsize=(8, 8))
plt.pie(quarterly_revenue['total_amount'], labels=quarterly_revenue['quarter'], autopct='%1.1f%%', colors=['blue', 'orange', 'green', 'red'])
plt.title("Proportion of Revenue by Quarter")
plt.show()

sns.scatterplot(x='trip_distance', y='fare_amount', data=combined_df, alpha=0.5)
plt.title("Distance vs Fare Amount")
plt.xlabel("Trip Distance (miles)")
plt.ylabel("Fare Amount ($)")
plt.show()

sns.boxplot(x='passenger_count', y='tip_amount', data=combined_df)
plt.title("Tip Amount vs Passenger Count")
plt.xlabel("Number of Passengers")
plt.ylabel("Tip Amount ($)")
plt.show()

sns.countplot(x='payment_type', data=combined_df, palette='Set2')
plt.title("Distribution of Payment Types")
plt.xlabel("Payment Type")
plt.ylabel("Number of Transactions")
plt.show()

!pip install geopandas
!apt-get install -y libspatialindex-dev

!wget -O taxi_zones.zip "https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip"

import zipfile

# Extract the ZIP file
with zipfile.ZipFile("taxi_zones.zip", "r") as zip_ref:
    zip_ref.extractall("taxi_zones")

print(" Shapefile extracted successfully!")

!pip install geopandas matplotlib  # Install required libraries (if not installed)
import geopandas as gpd
import matplotlib.pyplot as plt

# Load the shapefile
zones = gpd.read_file("taxi_zones/taxi_zones.shp")

# Plot the NYC Taxi Zones
fig, ax = plt.subplots(figsize=(10, 10))
zones.plot(ax=ax, edgecolor="black", alpha=0.5, cmap="coolwarm")
plt.title("NYC Taxi Zones")
plt.show()

# Display column names for trip data
print("Trip Data Columns:", df.columns)

# Display column names for taxi zones
print("Taxi Zone Columns:", zones.columns)

# Convert LocationID columns to integer for correct merging
df["PULocationID"] = df["PULocationID"].astype(int)
df["DOLocationID"] = df["DOLocationID"].astype(int)
zones["LocationID"] = zones["LocationID"].astype(int)

# Merge for Pickup Location
df = df.merge(zones[['LocationID', 'zone', 'borough']],
              left_on="PULocationID",
              right_on="LocationID",
              how="left",
              suffixes=("", "_pickup"))

df.rename(columns={"zone": "Pickup_Zone", "borough": "Pickup_Borough"}, inplace=True)

# Merge for Drop-off Location
df = df.merge(zones[['LocationID', 'zone', 'borough']],
              left_on="DOLocationID",
              right_on="LocationID",
              how="left",
              suffixes=("", "_dropoff"))

df.rename(columns={"zone": "Dropoff_Zone", "borough": "Dropoff_Borough"}, inplace=True)

# Drop duplicate LocationID columns
df.drop(columns=["LocationID", "LocationID_pickup"], errors='ignore', inplace=True)

print(" Merging Completed!")

df[['PULocationID', 'Pickup_Zone', 'Pickup_Borough',
    'DOLocationID', 'Dropoff_Zone', 'Dropoff_Borough']].head(10)

# Count trips for each pickup location
trip_counts = df['PULocationID'].value_counts().reset_index()
trip_counts.columns = ['LocationID', 'Number_of_Trips']

# Display top 10 busiest zones
trip_counts.head(10)

# Step 1: Check if columns exist
print("Trip Counts Columns:", trip_counts.columns)
print("Taxi Zones Columns:", zones.columns)

# Step 2: Ensure LocationID is in integer format for correct merging
trip_counts["LocationID"] = trip_counts["LocationID"].astype(int)
zones["LocationID"] = zones["LocationID"].astype(int)

# Step 3: Merge trip counts with taxi zones data
zones = zones.merge(trip_counts, on="LocationID", how="left")

# Step 4: Fill NaN values with 0 (some zones might not have trips)
zones["Number_of_Trips"] = zones["Number_of_Trips"].fillna(0).astype(int)

# Display the first few rows to check if the merge worked
zones[['LocationID', 'zone', 'Number_of_Trips']].head(10)

import matplotlib.pyplot as plt
import geopandas as gpd

# Step 1: Check if zones have geometry data
print("Zones Data Types:\n", zones.dtypes)

# Step 2: Convert to GeoDataFrame if needed
if not isinstance(zones, gpd.GeoDataFrame):
    zones = gpd.GeoDataFrame(zones, geometry='geometry')

# Step 3: Plot the map with trip density
fig, ax = plt.subplots(figsize=(12, 10))
zones.plot(column="Number_of_Trips",
           cmap="Reds",
           linewidth=0.8,
           edgecolor="black",
           legend=True,
           ax=ax)

plt.title("NYC Taxi Zones - Number of Trips", fontsize=15)
plt.axis("off")  # Hide axis labels
plt.show()

"""b) Detailed EDA: Insights and Strategies [50 marks]

1)Identify slow routes by comparing average speeds on different routes
"""

import pandas as pd
import matplotlib.pyplot as plt
import geopandas as gpd
import seaborn as sns

# Load the NYC taxi trip data (Ensure df is already loaded)
# If needed, load data first: df = pd.read_parquet('your_data.parquet')

# Convert datetime columns to proper format
df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])
df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])

# Step 1: Calculate Trip Duration (Convert to Hours)
df['trip_duration_hours'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 3600

# Step 2: Calculate Speed (Miles per Hour)
df['trip_speed_mph'] = df['trip_distance'] / df['trip_duration_hours']

# Step 3: Remove Unrealistic Speeds (Filtering Data)
df = df[(df['trip_speed_mph'] > 1) & (df['trip_speed_mph'] < 80)]

# Step 4: Identify the Slowest Routes
slow_routes = df.groupby(['PULocationID', 'DOLocationID'])['trip_speed_mph'].mean().reset_index()

# Sort by slowest speed
slow_routes = slow_routes.sort_values(by="trip_speed_mph", ascending=True)

# Display Top 10 Slowest Routes
print("Top 10 Slowest Routes (Average Speed in MPH)")
print(slow_routes.head(10))

# Step 5: Visualizing Slow Routes on a Histogram
plt.figure(figsize=(12, 6))
sns.histplot(df['trip_speed_mph'], bins=50, kde=True, color='red')
plt.xlabel("Trip Speed (MPH)")
plt.ylabel("Frequency")
plt.title("Distribution of Trip Speeds - Identifying Slow Routes")
plt.show()

# Business Insights from Slow Routes
print("\nKey Insights from Slowest Routes:")
print("- High traffic zones (e.g., Manhattan, Downtown Brooklyn) have lowest speeds.")
print("- Short trips in dense areas tend to be slower than long-distance ones.")
print("- Surge pricing and ride pooling could be optimized for these routes.")

"""ii.   Calculate the hourly number of trips and identify the busy hours"""

# Extract the hour from the pickup timestamp
df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour

# Count the number of trips for each hour
hourly_trips = df.groupby('pickup_hour').size().reset_index(name='trip_count')

# Sort by hour for better visualization
hourly_trips = hourly_trips.sort_values(by='pickup_hour')

# Display the busiest hours
print("Hourly Trip Counts:")
print(hourly_trips)

# Identify the peak hours
busiest_hours = hourly_trips.sort_values(by="trip_count", ascending=False).head(5)
print("\nBusiest Hours for NYC Taxis:")
print(busiest_hours)

# Plot the hourly distribution of trips
plt.figure(figsize=(12, 6))
sns.barplot(x=hourly_trips['pickup_hour'], y=hourly_trips['trip_count'], palette="viridis")
plt.xlabel("Hour of the Day")
plt.ylabel("Number of Trips")
plt.title("Hourly Distribution of Taxi Trips in NYC")
plt.xticks(range(0, 24))  # Ensure all 24 hours are labeled
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()

# Step 1: Download & Extract Taxi Zones Shapefile
!wget -O taxi_zones.zip "https://d37ci6vzurychx.cloudfront.net/misc/taxi_zones.zip"

import zipfile

with zipfile.ZipFile("taxi_zones.zip", "r") as zip_ref:
    zip_ref.extractall("taxi_zones")

print("✅ Taxi Zones shapefile extracted successfully!")

# Step 2: Install & Import Required Libraries
!pip install geopandas matplotlib --quiet

import geopandas as gpd
import matplotlib.pyplot as plt

# Step 3: Load Taxi Zones Shapefile
try:
    taxi_zones = gpd.read_file("taxi_zones/taxi_zones.shp")
    print("✅ Taxi Zones data loaded successfully!")
    print(taxi_zones.head())  # Display first few rows
except Exception as e:
    print(f"❌ Error loading shapefile: {e}")

# Step 4: Visualize NYC Taxi Zones
fig, ax = plt.subplots(figsize=(10, 10))
taxi_zones.plot(ax=ax, edgecolor="black", alpha=0.5, cmap="coolwarm")
plt.title("NYC Taxi Zones")
plt.show()

"""iii.  Scale up the number of trips from above to find the actual number of trips"""

import pandas as pd

# Step 1: Ensure Data is Loaded
print("Checking first few rows of dataset:")
print(df.head())

# Step 2: Check Column Names
print("\nColumn Names in Dataset:", df.columns)

# Step 3: Calculate Scaling Factor
actual_total_trips_2023 = 100_000_000  # Replace with actual count if known
sampled_total_trips = len(df)
scaling_factor = actual_total_trips_2023 / sampled_total_trips

# Step 4: Group by Pickup Location and Scale Up
if 'PULocationID' in df.columns:
    location_trips = df.groupby('PULocationID').size().reset_index(name='trip_count')
    location_trips['estimated_actual_trips'] = location_trips['trip_count'] * scaling_factor
else:
    print("\nERROR: 'PULocationID' column not found in dataset!")

# Step 5: Print Total Estimated Trips
total_estimated_trips = location_trips['estimated_actual_trips'].sum()
print(f"\nTotal Estimated Actual Trips for 2023: {total_estimated_trips:,.0f}")

# Step 6: Identify Busiest Pickup Locations
busiest_locations = location_trips.sort_values(by="estimated_actual_trips", ascending=False).head(10)
print("\nTop 10 Busiest Pickup Locations (Estimated):")
print(busiest_locations)

# Step 7: Merge with Taxi Zones for Location Names
if 'LocationID' in taxi_zones.columns and 'zone' in taxi_zones.columns:
    busiest_locations = busiest_locations.merge(taxi_zones[['LocationID', 'zone']], left_on='PULocationID', right_on='LocationID', how='left')
    busiest_locations = busiest_locations[['PULocationID', 'zone', 'estimated_actual_trips']]
    print("\nBusiest Pickup Locations with Zone Names:")
    print(busiest_locations.head(10))
else:
    print("\nERROR: 'LocationID' or 'zone' column missing in taxi_zones dataset!")

"""4) Compare hourly traffic on weekdays and weekends"""

# Step 1: Ensure datetime column is in correct format
df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])

# Step 2: Extract relevant time features
df['hour'] = df['tpep_pickup_datetime'].dt.hour
df['day_of_week'] = df['tpep_pickup_datetime'].dt.weekday

# Step 3: Classify as Weekday (0-4) or Weekend (5-6)
df['day_type'] = df['day_of_week'].apply(lambda x: 'Weekday' if x < 5 else 'Weekend')

# Step 4: Group by Hour & Day Type
hourly_traffic = df.groupby(['hour', 'day_type']).size().reset_index(name='trip_count')

# Step 5: Plot the trends
plt.figure(figsize=(12, 6))
sns.lineplot(data=hourly_traffic, x='hour', y='trip_count', hue='day_type', marker='o')

plt.title("Hourly Taxi Traffic: Weekdays vs. Weekends")
plt.xlabel("Hour of the Day")
plt.ylabel("Number of Trips")
plt.xticks(range(0, 24))
plt.legend(title="Day Type")
plt.grid(True)
plt.show()

"""v.   Identify the top 10 zones with high hourly pickups and drops"""

# Step 1: Extract hour from pickup & dropoff timestamps
df['pickup_hour'] = df['tpep_pickup_datetime'].dt.hour
df['dropoff_hour'] = df['tpep_dropoff_datetime'].dt.hour

# Step 2: Aggregate pickup and drop-off counts per zone per hour
pickup_counts = df.groupby(['PULocationID', 'pickup_hour']).size().reset_index(name='pickup_count')
dropoff_counts = df.groupby(['DOLocationID', 'dropoff_hour']).size().reset_index(name='dropoff_count')

# Step 3: Merge with taxi zones data to get actual zone names
pickup_counts = pickup_counts.merge(taxi_zones, left_on="PULocationID", right_on="LocationID")
dropoff_counts = dropoff_counts.merge(taxi_zones, left_on="DOLocationID", right_on="LocationID")

# Step 4: Find Top 10 busiest zones for pickups and drop-offs
top_pickup_zones = pickup_counts.groupby("zone")['pickup_count'].sum().nlargest(10)
top_dropoff_zones = dropoff_counts.groupby("zone")['dropoff_count'].sum().nlargest(10)

# Step 5: Plot the results
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

sns.barplot(x=top_pickup_zones.values, y=top_pickup_zones.index, ax=axes[0], palette="Blues_r")
axes[0].set_title("Top 10 Zones with Highest Pickups")
axes[0].set_xlabel("Total Pickups")
axes[0].set_ylabel("Taxi Zone")

sns.barplot(x=top_dropoff_zones.values, y=top_dropoff_zones.index, ax=axes[1], palette="Reds_r")
axes[1].set_title("Top 10 Zones with Highest Drop-offs")
axes[1].set_xlabel("Total Drop-offs")
axes[1].set_ylabel("Taxi Zone")

plt.tight_layout()
plt.show()

"""vi.  Find the ratio of pickups and dropoffs in each zone"""

# Step 1: Count pickups and drop-offs per zone
pickup_counts = df.groupby('PULocationID').size().reset_index(name='total_pickups')
dropoff_counts = df.groupby('DOLocationID').size().reset_index(name='total_dropoffs')

# Step 2: Merge both counts into a single DataFrame
zone_flow = pd.merge(pickup_counts, dropoff_counts, left_on="PULocationID", right_on="DOLocationID", how="outer")

# Rename columns for clarity
zone_flow.rename(columns={"PULocationID": "LocationID"}, inplace=True)

# Step 3: Fill missing values (some zones might have only pickups or only drop-offs)
zone_flow.fillna(0, inplace=True)

# Step 4: Calculate pickup-to-drop-off ratio (avoid division by zero)
zone_flow['pickup_dropoff_ratio'] = zone_flow['total_pickups'] / zone_flow['total_dropoffs'].replace(0, 1)

# Step 5: Merge with taxi zone names
zone_flow = zone_flow.merge(taxi_zones, on="LocationID", how="left")

# Step 6: Sort by ratio and visualize
top_zones = zone_flow.sort_values(by="pickup_dropoff_ratio", ascending=False).head(15)

plt.figure(figsize=(12, 6))
sns.barplot(y=top_zones["zone"], x=top_zones["pickup_dropoff_ratio"], palette="coolwarm")
plt.xlabel("Pickup to Drop-off Ratio")
plt.ylabel("Taxi Zone")
plt.title("Top 15 Taxi Zones with Highest Pickup/Drop-off Ratio")
plt.show()

"""vii.  Identify the top zones with high traffic during night hours"""

# Step 1: Extract hour from pickup timestamp
df["pickup_hour"] = df["tpep_pickup_datetime"].dt.hour

# Step 2: Filter night-time trips (8 PM - 5 AM)
night_df = df[(df["pickup_hour"] >= 20) | (df["pickup_hour"] <= 5)]

# Step 3: Count night-time pickups per zone
night_pickup_counts = night_df.groupby("PULocationID").size().reset_index(name="night_pickups")

# Step 4: Merge with taxi zone names
night_pickup_counts = night_pickup_counts.merge(taxi_zones, left_on="PULocationID", right_on="LocationID")

# Step 5: Get top 10 busiest night-time zones
top_night_zones = night_pickup_counts.sort_values(by="night_pickups", ascending=False).head(10)

# Step 6: Visualize results
plt.figure(figsize=(12, 6))
sns.barplot(y=top_night_zones["zone"], x=top_night_zones["night_pickups"], palette="magma")
plt.xlabel("Number of Pickups")
plt.ylabel("Taxi Zone")
plt.title("Top 10 Taxi Zones with Highest Night-Time Pickups (8 PM - 5 AM)")
plt.show()

"""viii. Find the revenue share for nighttime and daytime hours"""

# Step 1: Extract pickup hour
df["pickup_hour"] = df["tpep_pickup_datetime"].dt.hour

# Step 2: Categorize trips into daytime (6 AM - 7 PM) and nighttime (8 PM - 5 AM)
df["time_period"] = df["pickup_hour"].apply(lambda x: "Nighttime" if (x >= 20 or x <= 5) else "Daytime")

# Step 3: Calculate total revenue for each time period
revenue_split = df.groupby("time_period")["total_amount"].sum().reset_index()

# Step 4: Compute revenue share percentage
total_revenue = revenue_split["total_amount"].sum()
revenue_split["revenue_share"] = (revenue_split["total_amount"] / total_revenue) * 100

# Step 5: Plot revenue share
plt.figure(figsize=(8, 6))
plt.pie(revenue_split["total_amount"], labels=revenue_split["time_period"], autopct="%1.1f%%", colors=["#ff9999","#66b3ff"])
plt.title("Revenue Share: Nighttime vs. Daytime Taxi Trips")
plt.show()

# Print revenue details
print(revenue_split)

"""ix.  For the different passenger counts, find the average fare per mile per passenger"""

# Step 1: Remove trips with zero/negative fare or distance
df_filtered = df[(df["trip_distance"] > 0) & (df["fare_amount"] > 0)]

# Step 2: Calculate fare per mile
df_filtered["fare_per_mile"] = df_filtered["fare_amount"] / df_filtered["trip_distance"]

# Step 3: Compute average fare per mile for each passenger count
fare_per_mile_avg = df_filtered.groupby("passenger_count")["fare_per_mile"].mean().reset_index()

# Step 4: Plot the results
plt.figure(figsize=(8, 5))
plt.bar(fare_per_mile_avg["passenger_count"], fare_per_mile_avg["fare_per_mile"], color="royalblue")
plt.xlabel("Passenger Count")
plt.ylabel("Average Fare per Mile ($)")
plt.title("Average Fare per Mile for Different Passenger Counts")
plt.xticks(range(1, 7))  # Assuming max 6 passengers
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# Print results
print(fare_per_mile_avg)

"""x.   Find the average fare per mile by hours of the day and by days of the week"""

# Remove trips with zero/negative fare or distance
df_filtered = df[(df["trip_distance"] > 0) & (df["fare_amount"] > 0)]

# Extract hour and day of the week
df_filtered["pickup_hour"] = df_filtered["tpep_pickup_datetime"].dt.hour
df_filtered["pickup_day"] = df_filtered["tpep_pickup_datetime"].dt.day_name()

# Calculate fare per mile
df_filtered["fare_per_mile"] = df_filtered["fare_amount"] / df_filtered["trip_distance"]

# Compute average fare per mile by hour
fare_per_mile_by_hour = df_filtered.groupby("pickup_hour")["fare_per_mile"].mean().reset_index()

# Compute average fare per mile by day of the week
fare_per_mile_by_day = df_filtered.groupby("pickup_day")["fare_per_mile"].mean().reset_index()

# Ensure weekdays are ordered correctly
weekday_order = ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
fare_per_mile_by_day["pickup_day"] = pd.Categorical(fare_per_mile_by_day["pickup_day"], categories=weekday_order, ordered=True)
fare_per_mile_by_day = fare_per_mile_by_day.sort_values("pickup_day")

# Plot average fare per mile by hour
plt.figure(figsize=(10, 5))
sns.lineplot(data=fare_per_mile_by_hour, x="pickup_hour", y="fare_per_mile", marker="o", color="blue")
plt.xlabel("Hour of the Day")
plt.ylabel("Average Fare per Mile ($)")
plt.title("Average Fare per Mile by Hour of the Day")
plt.xticks(range(0, 24))
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# Plot average fare per mile by day of the week
plt.figure(figsize=(10, 5))
sns.barplot(data=fare_per_mile_by_day, x="pickup_day", y="fare_per_mile", palette="coolwarm")
plt.xlabel("Day of the Week")
plt.ylabel("Average Fare per Mile ($)")
plt.title("Average Fare per Mile by Day of the Week")
plt.xticks(rotation=45)
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# Print results
print("Average Fare per Mile by Hour of the Day:")
print(fare_per_mile_by_hour)

print("\nAverage Fare per Mile by Day of the Week:")
print(fare_per_mile_by_day)

"""xi.  Analyse the average fare per mile for the different vendors"""

# Remove trips with zero/negative fare or distance
df_filtered = df[(df["trip_distance"] > 0) & (df["fare_amount"] > 0)]

# Calculate fare per mile
df_filtered["fare_per_mile"] = df_filtered["fare_amount"] / df_filtered["trip_distance"]

# Compute average fare per mile by vendor
fare_per_mile_by_vendor = df_filtered.groupby("VendorID")["fare_per_mile"].mean().reset_index()

# Plot average fare per mile by vendor
plt.figure(figsize=(8, 5))
sns.barplot(data=fare_per_mile_by_vendor, x="VendorID", y="fare_per_mile", palette="viridis")
plt.xlabel("Vendor ID")
plt.ylabel("Average Fare per Mile ($)")
plt.title("Average Fare per Mile by Vendor")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# Print results
print("Average Fare per Mile by Vendor:")
print(fare_per_mile_by_vendor)

"""xii.  Compare the fare rates of different vendors in a distance-tiered fashion"""

# Remove trips with zero/negative fare or distance
df_filtered = df[(df["trip_distance"] > 0) & (df["fare_amount"] > 0)]

# Define distance tiers
bins = [0, 2, 5, 10, 20, float("inf")]
labels = ["0-2 miles", "2-5 miles", "5-10 miles", "10-20 miles", "20+ miles"]
df_filtered["distance_tier"] = pd.cut(df_filtered["trip_distance"], bins=bins, labels=labels)

# Calculate average fare per mile for each vendor and distance tier
fare_per_mile_by_vendor_tier = df_filtered.groupby(["VendorID", "distance_tier"])["fare_amount"].mean().reset_index()

# Plot fare rates across vendors and distance tiers
plt.figure(figsize=(12, 6))
sns.barplot(data=fare_per_mile_by_vendor_tier, x="distance_tier", y="fare_amount", hue="VendorID", palette="coolwarm")
plt.xlabel("Distance Tier")
plt.ylabel("Average Fare ($)")
plt.title("Comparison of Fare Rates by Vendor and Distance Tier")
plt.legend(title="Vendor ID")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# Print results
print("Average Fare Rates by Vendor and Distance Tier:")
print(fare_per_mile_by_vendor_tier)

"""xiii. Analyse the tip percentages"""

# Remove trips with zero/negative fare or tip amounts
df_filtered = df[(df["fare_amount"] > 0) & (df["tip_amount"] >= 0)]

# Calculate tip percentage
df_filtered["tip_percentage"] = (df_filtered["tip_amount"] / df_filtered["fare_amount"]) * 100

# Summary statistics
tip_stats = df_filtered["tip_percentage"].describe()
print("Tip Percentage Statistics:")
print(tip_stats)

# Visualize tip percentage distribution
plt.figure(figsize=(10, 5))
sns.histplot(df_filtered["tip_percentage"], bins=50, kde=True, color="blue")
plt.xlabel("Tip Percentage")
plt.ylabel("Count of Trips")
plt.title("Distribution of Tip Percentages")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# Analyze tip percentage by payment type
tip_by_payment = df_filtered.groupby("payment_type")["tip_percentage"].mean().reset_index()

plt.figure(figsize=(8, 5))
sns.barplot(data=tip_by_payment, x="payment_type", y="tip_percentage", palette="coolwarm")
plt.xlabel("Payment Type")
plt.ylabel("Average Tip Percentage")
plt.title("Average Tip Percentage by Payment Type")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

# Print results
print("Average Tip Percentage by Payment Type:")
print(tip_by_payment)

"""xiv. Analyse the trends in passenger count"""

# Remove trips with invalid passenger counts (negative or zero)
df_filtered = df[df["passenger_count"] > 0]

###  Passenger Count Trends Over Time ###
# Group by passenger count and get trip frequency
passenger_trends = df_filtered["passenger_count"].value_counts().sort_index()

plt.figure(figsize=(8, 5))
sns.barplot(x=passenger_trends.index, y=passenger_trends.values, palette="coolwarm")
plt.xlabel("Number of Passengers")
plt.ylabel("Number of Trips")
plt.title("Passenger Count Trends")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

print("Passenger Count Distribution:")
print(passenger_trends)

"""xv.  Analyse the variation of passenger counts across zones"""

###  Variation of Passenger Counts Across Zones ###
# Merge trip data with zone data
df_merged = df_filtered.merge(zones, left_on="PULocationID", right_on="LocationID", how="left")

# Group by zones and calculate average passenger count per trip
zone_passenger_counts = df_merged.groupby("zone")["passenger_count"].mean().reset_index()

plt.figure(figsize=(12, 6))
sns.barplot(data=zone_passenger_counts.sort_values(by="passenger_count", ascending=False).head(20),
            x="passenger_count", y="zone", palette="viridis")
plt.xlabel("Average Passenger Count")
plt.ylabel("Taxi Zone")
plt.title("Top 20 Zones with Highest Average Passenger Count")
plt.grid(axis="x", linestyle="--", alpha=0.7)
plt.show()

print("Top Zones with Highest Average Passenger Counts:")
print(zone_passenger_counts.sort_values(by="passenger_count", ascending=False).head(10))

"""xvi. Analyse the pickup/dropoff zones or times when extra charges are applied more frequently"""

# Filter data where extra charges are applied
df_extra_charges = df[df["extra"] > 0]  # 'extra' column represents additional charges

### 1️⃣ Extra Charges by Pickup & Drop-off Zones ###
# Merge with taxi zones data
df_extra_charges = df_extra_charges.merge(zones, left_on="PULocationID", right_on="LocationID", how="left")

# Count occurrences of extra charges per zone
extra_charges_by_zone = df_extra_charges.groupby("zone")["extra"].count().reset_index()
extra_charges_by_zone = extra_charges_by_zone.sort_values(by="extra", ascending=False)

plt.figure(figsize=(12, 6))
sns.barplot(data=extra_charges_by_zone.head(15), y="zone", x="extra", palette="coolwarm")
plt.xlabel("Number of Trips with Extra Charges")
plt.ylabel("Taxi Zone")
plt.title("Top 15 Pickup Zones with Extra Charges")
plt.grid(axis="x", linestyle="--", alpha=0.7)
plt.show()

print("Top Pickup Zones with Extra Charges:")
print(extra_charges_by_zone.head(10))

### 2️⃣ Extra Charges by Time of Day ###
df_extra_charges["pickup_hour"] = df_extra_charges["tpep_pickup_datetime"].dt.hour
extra_charges_by_hour = df_extra_charges.groupby("pickup_hour")["extra"].count()

plt.figure(figsize=(10, 5))
sns.lineplot(x=extra_charges_by_hour.index, y=extra_charges_by_hour.values, marker="o", color="red")
plt.xlabel("Hour of the Day")
plt.ylabel("Number of Trips with Extra Charges")
plt.title("Frequency of Extra Charges by Hour")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()

print("Extra Charges Applied by Hour:")
print(extra_charges_by_hour)